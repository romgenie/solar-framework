"""
This module implements a simple consumer API for SOLAR using Flask.
It exposes endpoints for both Topological Rewarding (inference scaling) and Hybrid Scaling inference.

Endpoints:
- /infer/topological: Uses the Topological Rewarding component to process a problem statement.
- /infer/hybrid: Uses the Hybrid Scaling component (combining fine-tuned model and reward model) for inference.

Both endpoints expect a JSON payload with a "problem_statement" field and return the selected reasoning topology,
the corresponding response, the reward score, and all generated responses from different topologies.
"""

from flask import Flask, request, jsonify
from solar_topological_rewarding import InferencePipeline as TopologicalInferencePipeline
from solar_hybrid_scaling import HybridScalingInference

app = Flask(__name__)

@app.route("/infer/topological", methods=["POST"])
def infer_topological():
    """
    Endpoint for inference using the Topological Rewarding component.
    
    Expects:
        JSON payload with:
            - problem_statement (str): The problem statement to solve.
    
    Returns:
        JSON response with:
            - selected_topology (str): The name of the topology with the optimal response.
            - response (str): The selected reasoning response.
            - score (float): The reward score of the selected response.
            - all_responses (dict): All responses generated by each topology.
    """
    data = request.get_json()
    problem_statement = data.get("problem_statement", "")
    if not problem_statement:
        return jsonify({"error": "problem_statement is required"}), 400
    
    pipeline = TopologicalInferencePipeline()
    result = pipeline.process_request(problem_statement)
    return jsonify(result)

@app.route("/infer/hybrid", methods=["POST"])
def infer_hybrid():
    """
    Endpoint for inference using the Hybrid Scaling component.
    
    Expects:
        JSON payload with:
            - problem_statement (str): The problem statement to solve.
    
    Returns:
        JSON response with:
            - selected_topology (str): The name of the topology with the optimal fine-tuned response.
            - response (str): The selected fine-tuned reasoning response.
            - score (float): The reward score of the selected response.
            - all_responses (dict): All responses generated by each topology.
    """
    data = request.get_json()
    problem_statement = data.get("problem_statement", "")
    if not problem_statement:
        return jsonify({"error": "problem_statement is required"}), 400
    
    hybrid_pipeline = HybridScalingInference()
    result = hybrid_pipeline.process_request(problem_statement)
    return jsonify(result)

if __name__ == "__main__":
    # Run the Flask application on port 5000
    app.run(host="0.0.0.0", port=5000, debug=True)